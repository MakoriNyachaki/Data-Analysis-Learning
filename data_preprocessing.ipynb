{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f301253",
   "metadata": {},
   "source": [
    "#### Numpy Data Preprocessing\n",
    "\n",
    "##### Why Data Preprocessing\n",
    "1. Data Quality - Data preprocessing allows us to clean and enhance data quality, ensuring reliable analysis.\n",
    "2. Feature Engineering - Helps in creating meaningful features which are the building blocks of ML algorithms\n",
    "3. Scaling and Normalization - Brings data into a consistent range, preventing certain featurs from dominating others.\n",
    "4. Handling Categorical Data - It enable transformation of categorical data into a format that ML algorithms can understand.\n",
    "\n",
    "##### Why Numpy is Indispensable for Data Preprocessing\n",
    "\n",
    "1. Efficient Array Operations - It is highly efficient in performing Mathematical and logical operations, thus, its speed is critical for large datasets.\n",
    "2. Handling Missing Data - it offers tools that help in handling missing data sealing the gaps in the data which may compromise the analysis.\n",
    "3. Statistical Calculations - It provides functions to calculate statistics, which are essential for data cleaning and understanding your data's distribution.\n",
    "4. Array Slicing and Indexing - This makes it easier to extract specific portions of data a crucial skill for selecting and transforming features.\n",
    "5. Numerical Encoding - Helps tranform categoricl data into a numerical format through techniques like one-hot encoding.\n",
    "\n",
    "##### Handling Missing Values\n",
    "- We use function such as:\n",
    "```nan```,\n",
    "```isnan()```,\n",
    "```nanmean()``` (which calculates the mean of non-missing values).\n",
    "- Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd468fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280e3257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "# Create an array with a missing value\n",
    "\n",
    "data = np.array([1, 2, np.nan, 4, 5])\n",
    "\n",
    "# Calculate the mean of non-missing values\n",
    "mean_val = np.nanmean(data)\n",
    "\n",
    "# Assign the mean to the missing value\n",
    "data[np.isnan(data)] = mean_val\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b89bec",
   "metadata": {},
   "source": [
    "##### Detecting Outliers\n",
    "```z_score``` - The Z-score measures how far each data point is from the mean in terms of standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f154697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array with outliers\n",
    "data = np.array([1, 2, 3, 4, 100, 200])\n",
    "\n",
    "# Calculate the z_scores\n",
    "z_score = (data - np.mean(data)) / np.std(data)\n",
    "#print(z_score)\n",
    "\n",
    "# Identify and remove outliers (where absolute Z-score > 3)\n",
    "outliers = np.where(np.abs(z_score) > 3)\n",
    "filtered_data = data[outliers]\n",
    "#print(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7322d93",
   "metadata": {},
   "source": [
    "##### Scaling and Normalization\n",
    "- This ensures that your data lies within a consistent range.\n",
    "- Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "752c5f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# Create an array\n",
    "data = np.array([10,20,30,40,50, 60])\n",
    "\n",
    "# Perform min-max scaling(scaling to [0, 1]) range\n",
    "scaled_data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5093b79f",
   "metadata": {},
   "source": [
    "**Explanantion:** In this example, we perform Min-Max scaling to rescale the data values to the range [0, 1]. We achieve this by subtracting the minimum value from each data point and dividing by the range (the difference between the maximum and minimum values). Min-Max scaling is useful when different features have different scales, and we want to bring them to a consistent range for modeling.\n",
    "\n",
    "##### Encoding Categorica Data\n",
    "- Numpy helps convert categorical variables into numerical representations using techniques like _one-hut_ encoding.\n",
    "- Example: One-hut Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "352ccca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Create an array with categorical data\n",
    "colors = np.array(['red', 'yellow', 'green', 'yellow', 'blue', 'black','yellow', 'red', 'violet'])\n",
    "\n",
    "# Perform one-hot encoding\n",
    "encoded_colors = np.eye(len(np.unique(colors)))[np.searchsorted(np.unique(colors), colors)]\n",
    "\n",
    "print(encoded_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7b5650",
   "metadata": {},
   "source": [
    "**Explanation:** A colors categorical data. We first identify unique categories using np.unique(), and then we use np.searchsorted() to map each categorical value to a numerical index. Finally, we use np.eye() to perform one-hot encoding, where each category is represented as a binary vector, indicating the presence or absence of each category. This technique ensures that categorical data can be used in machine learning models effectively.\n",
    "- Example 2\n",
    "Extacting day of the week from dates, import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dcb1792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([5, 1, 3], dtype='int32')\n"
     ]
    }
   ],
   "source": [
    "# Create an array of date strings\n",
    "dates = np.array(['2026-08-01', '2026-09-01', '2026-10-01'])\n",
    "\n",
    "# Convert to date objects\n",
    "date_objs = pd.to_datetime(dates)\n",
    "\n",
    "# Extract day of the week\n",
    "day_of_week = date_objs.dayofweek\n",
    "\n",
    "print(day_of_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dbe82b",
   "metadata": {},
   "source": [
    "**Explanation:** Here we demonstrate how to work with date and time data. We first convert date strings into datetime objects and then extract the day of the week. This can be useful for time series analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddecfa0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
